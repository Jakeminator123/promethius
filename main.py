#!/usr/bin/env python3
# main.py â€“ central startpunkt som fÃ¶rst rensar och sedan startar scraping
# PÃ¥ Render startar ocksÃ¥ webservern fÃ¶r att ha allt i en robust process

from __future__ import annotations
import argparse
import sys
import os
import time
import datetime
import subprocess
from pathlib import Path
import signal
import threading
from typing import Any

# Import centraliserad path-hantering
sys.path.append(str(Path(__file__).resolve().parent))
from utils.paths import PROJECT_ROOT, POKER_DB, IS_RENDER

# â”€â”€ 1. Hitta projektroten och fÃ¶rbered import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = PROJECT_ROOT
DB_PATH = POKER_DB.relative_to(ROOT) if not IS_RENDER else POKER_DB

print(f"ğŸ  Projektrot: {ROOT}")
print(f"ğŸ’¾ Database: {POKER_DB}")

os.chdir(ROOT)
from scrape_hh import scrape  # type: ignore[reportMissingImports]  # noqa: E402

def start_webserver_thread():
    """Startar webservern i en separat thread (bara pÃ¥ Render)"""
    if not IS_RENDER:
        return
        
    print("ğŸŒ Startar webserver-thread...")
    
    def run_webserver():
        try:
            subprocess.run([sys.executable, "start_server.py"])
        except Exception as e:
            print(f"âŒ Webserver-thread krashade: {e}")
    
    web_thread = threading.Thread(target=run_webserver, daemon=True)
    web_thread.start()
    
    # VÃ¤nta lite sÃ¥ webservern hinner starta
    time.sleep(5)
    print("âœ… Webserver-thread startad")

# â”€â”€ 2. HjÃ¤lpfunktioner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_config() -> dict[str, str]:
    kv: dict[str, str] = {}
    with open(ROOT / "config.txt", encoding="utf-8") as fh:
        for line in fh:
            if "=" in line:
                k, v = line.strip().split("=", 1)
                kv[k.strip().upper()] = v.strip()
    return kv

CFG = load_config()
STARTING_DATE = CFG["STARTING_DATE"]

print(f"ğŸŒ API: {CFG['BASE_URL']}")
print(f"   Organizer: {CFG['ORGANIZER']}")
print(f"   Event: {CFG['EVENT']}")
print()

def run_clean_start(skip_on_render: bool = True) -> bool:
    # PÃ¥ Render, skippa rensning om inte explicit begÃ¤rt
    if IS_RENDER and skip_on_render:
        print("ğŸš€ PÃ¥ Render - hoppar Ã¶ver rensning (anvÃ¤nd skip_on_render=False fÃ¶r att tvinga)")
        return True
        
    try:
        print("ğŸ§¹ KÃ¶r rensning...")
        result = subprocess.run([sys.executable, "clean_start.py"],
                                cwd=ROOT, capture_output=True, text=True, timeout=60)

        if result.returncode == 0:
            print("âœ… Rensning klar")
            if result.stdout.strip():
                print(f"   {result.stdout.strip()}")
            return True
        else:
            print(f"âŒ Rensning misslyckades: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("â° Rensning tog fÃ¶r lÃ¥ng tid - avbryter")
        return False
    except Exception as e:
        print(f"âŒ Fel vid rensning: {e}")
        return False

def run_fetch_process(date_str: str, url: str | None, db: str | None,
                      skip_scripts: list[str] | None = None, no_scripts: bool = False) -> None:
    try:
        argv = ["scrape.py", date_str]
        if url:
            argv += ["--url", url]
        if db:
            argv += ["--db", db]
        if skip_scripts:
            argv += ["--skip-scripts"] + skip_scripts
        if no_scripts:
            argv += ["--no-scripts"]

        original_argv = sys.argv[:]
        sys.argv = argv

        scrape.main()

        sys.argv = original_argv

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  Scraping avbrutet fÃ¶r {date_str}")
        raise
    except Exception as e:
        print(f"âŒ Fel vid scraping fÃ¶r {date_str}: {e}")
        raise

def run_single_fetch(date_str: str, url: str | None, db: str | None,
                     skip_scripts: list[str] | None = None, no_scripts: bool = False) -> None:
    if not run_clean_start():
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return

    run_fetch_process(date_str, url, db, skip_scripts, no_scripts)

def run_loop(start_date: str, url: str | None, db: str | None,
             sleep_s: int = 300, max_workers: int = 1,
             skip_scripts: list[str] | None = None, no_scripts: bool = False,
             no_clean: bool = False) -> None:
    # PÃ¥ Render, kÃ¶r rensning vid fÃ¶rsta start om inte --no-clean
    if IS_RENDER and not no_clean:
        # Kolla om det Ã¤r fÃ¶rsta kÃ¶rningen (databaser finns inte eller Ã¤r tomma)
        from utils.paths import POKER_DB, HEAVY_DB
        first_run = not POKER_DB.exists() or POKER_DB.stat().st_size < 1000
        
        if first_run:
            print("ğŸ§¹ FÃ¶rsta kÃ¶rningen pÃ¥ Render - rensar databaser...")
            if not run_clean_start(skip_on_render=False):
                print("âŒ Kritisk: Kan inte starta utan lyckad fÃ¶rsta rensning")
                sys.exit(1)
        else:
            print("â™»ï¸  Databaser finns redan - skippar rensning (kontinuerlig drift)")
    elif not no_clean and not run_clean_start():
        # Lokal miljÃ¶ - respektera --no-clean flaggan
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return

    day = datetime.date.fromisoformat(start_date)

    def signal_handler(signum: int, frame: Any) -> None:
        if IS_RENDER and signum == signal.SIGTERM:
            # PÃ¥ Render ignorerar vi SIGTERM fÃ¶r kontinuerlig drift
            print(f"\nğŸ›¡ï¸  Fick SIGTERM pÃ¥ Render - fortsÃ¤tter kÃ¶ra (kontinuerlig drift)")
            return
        print(f"\nğŸ›‘ Fick signal {signum} - stÃ¤nger av gracefully...")
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    batch_size = CFG.get("BATCH_SIZE", "500")
    print(f"ğŸ”„ Startar loop frÃ¥n {start_date}")
    print(f"   Batch-storlek: {batch_size} hÃ¤nder per dag")

    while True:
        try:
            current_date = day.isoformat()

            # KÃ¶r scraping synkront fÃ¶r att undvika extra processfork och sÃ¤nka CPU-toppar
            run_fetch_process(current_date, url, db, skip_scripts, no_scripts)

            day += datetime.timedelta(days=1)

            if day == datetime.date.today():
                print("ğŸ•‘ VÃ¤ntar 10 minuter innan nÃ¤sta kÃ¶rning...")
                time.sleep(600)
            else:
                print(f"ğŸ•‘ VÃ¤ntar {sleep_s//60} min innan nÃ¤sta kÃ¶rning...")
                time.sleep(sleep_s)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  Loop avbruten av anvÃ¤ndare")
            break
        except Exception as e:
            print(f"âŒ Fel i loop: {e}")
            print(f"â­ï¸  Hoppar Ã¶ver {day.isoformat()} och fortsÃ¤tter...")
            day += datetime.timedelta(days=1)
            time.sleep(5)

# â”€â”€ 3. CLI-parse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ap = argparse.ArgumentParser(
    description="Automatisk poker scraping system"
)
_ = ap.add_argument("--date", help="Startdatum (default = STARTING_DATE frÃ¥n config.txt)")
_ = ap.add_argument("--url", help="Ã–verskriv BASE_URL")
_ = ap.add_argument("--db", help="Ã–verskriv DB-sÃ¶kvÃ¤g")
_ = ap.add_argument("--workers", type=int, default=1,
                    help="Antal worker-processer (default: 1)")
_ = ap.add_argument("--sleep", type=int, default=300,
                    help="Sovtid i sekunder mellan kÃ¶rningar (default: 300)")
_ = ap.add_argument("--skip-scripts", nargs="*", default=[],
                    help="Script att hoppa Ã¶ver")
_ = ap.add_argument("--no-scripts", action="store_true",
                    help="Hoppa Ã¶ver alla processing-scripts")
_ = ap.add_argument("--no-clean", action="store_true",
                    help="Hoppa Ã¶ver rensning (rekommenderat pÃ¥ Render)")

args = ap.parse_args()

# â”€â”€ 4. KÃ¶r vald handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸš€ Startar automatisk scraping...")
    
    # PÃ¥ Render, starta webservern fÃ¶rst
    if IS_RENDER:
        start_webserver_thread()
        print("ğŸŒ Render: Webserver + Scraping i samma process fÃ¶r maximal stabilitet")
    
    start = args.date or STARTING_DATE
    run_loop(
        start, 
        args.url, 
        args.db, 
        args.sleep, 
        args.workers,
        args.skip_scripts, 
        args.no_scripts, 
        args.no_clean
    )
