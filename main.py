#!/usr/bin/env python3
# main.py â€“ central startpunkt som fÃ¶rst rensar och sedan startar scraping
# PÃ¥ Render startar ocksÃ¥ webservern fÃ¶r att ha allt i en robust process

from __future__ import annotations
import argparse
import sys
import os
import time
import datetime
import subprocess
import sqlite3
from pathlib import Path
import signal
import threading
from typing import Any
import psutil  # FÃ¶r process-hantering
import socket

# Import centraliserad path-hantering
sys.path.append(str(Path(__file__).resolve().parent))
from utils.paths import PROJECT_ROOT, POKER_DB, IS_RENDER

# â”€â”€ 1. Hitta projektroten och fÃ¶rbered import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = PROJECT_ROOT
DB_PATH = POKER_DB.relative_to(ROOT) if not IS_RENDER else POKER_DB

print(f"ğŸ  Projektrot: {ROOT}")
print(f"ğŸ’¾ Database: {POKER_DB}")

# â”€â”€ CLEANUP-FUNKTIONER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def kill_old_processes():
    """DÃ¶dÃ¤r gamla Python-processer som kÃ¶r scraping/webserver"""
    if not IS_RENDER:
        return  # Bara pÃ¥ Render
        
    try:
        current_pid = os.getpid()
        killed_count = 0
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                # Skippa vÃ¥r egen process
                if proc.info['pid'] == current_pid:
                    continue
                    
                # Leta efter andra Python-processer som kÃ¶r vÃ¥ra scripts
                if (proc.info['name'] in ['python', 'python3', 'python.exe'] and 
                    proc.info['cmdline'] and 
                    any('main.py' in str(cmd) or 'scrape.py' in str(cmd) or 'app.py' in str(cmd) 
                        for cmd in proc.info['cmdline'])):
                    
                    print(f"ğŸ”ª DÃ¶dÃ¤r gammal process: PID {proc.info['pid']} - {' '.join(proc.info['cmdline'][:3])}")
                    proc.terminate()
                    killed_count += 1
                    
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
                
        if killed_count > 0:
            print(f"âœ… DÃ¶dade {killed_count} gamla processer")
            time.sleep(2)  # VÃ¤nta sÃ¥ processer hinner dÃ¶
        else:
            print("âœ… Inga gamla processer att dÃ¶da")
            
    except Exception as e:
        print(f"âš ï¸  Kunde inte dÃ¶da gamla processer: {e}")

def cleanup_database_locks():
    """Rensar SQLite WAL/SHM-filer och stÃ¤nger lÃ¥sningar - HITTAR ALLA DATABASER"""
    try:
        from utils.paths import POKER_DB, HEAVY_DB, DB_DIR
        
        print("ğŸ” SÃ¶ker efter ALLA databas-filer rekursivt...")
        
        # Lista Ã¶ver alla databas-relaterade filer (kÃ¤nda paths)
        known_db_files = [
            POKER_DB,
            HEAVY_DB,
            POKER_DB.with_suffix('.db-wal'),
            POKER_DB.with_suffix('.db-shm'), 
            HEAVY_DB.with_suffix('.db-wal'),
            HEAVY_DB.with_suffix('.db-shm'),
        ]
        
        # SÃ¶k rekursivt efter ALLA databas-filer i hela data-omrÃ¥det
        search_dirs = [DB_DIR]
        if IS_RENDER:
            search_dirs.append(Path('/var/data'))
        
        all_db_files = []
        for search_dir in search_dirs:
            if search_dir.exists():
                # Hitta alla filer som matchar vÃ¥ra databas-namn
                patterns = ['poker.db*', 'heavy_analysis.db*']
                for pattern in patterns:
                    all_db_files.extend(search_dir.rglob(pattern))
        
        # Kombinera kÃ¤nda + hittade filer
        unique_db_files = list(set(known_db_files + all_db_files))
        
        print(f"   ğŸ“ Hittade {len(unique_db_files)} databas-relaterade filer")
        for db_file in unique_db_files:
            if db_file.exists():
                print(f"      â€¢ {db_file}")
        
        # FÃ¶rsÃ¶k stÃ¤nga alla SQLite-connections fÃ¶rst (bara .db-filer)
        for db_file in unique_db_files:
            if db_file.suffix == '.db' and db_file.exists():
                try:
                    # Ã–ppna kort connection fÃ¶r att trigga WAL checkpoint
                    conn = sqlite3.connect(str(db_file))
                    conn.execute("PRAGMA wal_checkpoint(TRUNCATE)")
                    conn.close()
                    print(f"   âœ“ Checkpoint: {db_file.name}")
                except Exception as e:
                    print(f"   âš ï¸  Checkpoint misslyckades fÃ¶r {db_file.name}: {e}")
        
        # Radera WAL/SHM-filer som kan vara lÃ¥sta
        removed_count = 0
        for db_file in unique_db_files:
            if db_file.name.endswith(('.db-wal', '.db-shm')) and db_file.exists():
                try:
                    db_file.unlink()
                    print(f"   âœ“ Raderade lÃ¥st fil: {db_file}")
                    removed_count += 1
                except Exception as e:
                    print(f"   âš ï¸  Kunde inte radera {db_file}: {e}")
        
        if removed_count > 0:
            print(f"âœ… Rensade {removed_count} lÃ¥sta databas-filer")
        else:
            print("âœ… Inga lÃ¥sta databas-filer att rensa")
            
    except Exception as e:
        print(f"âš ï¸  Fel vid databas-rensning: {e}")

def force_cleanup_on_start():
    """TvÃ¥ngsmÃ¤ssig cleanup vid start - dÃ¶dÃ¤r allt som kan stÃ¶ra"""
    if not IS_RENDER:
        return
        
    print("ğŸ§¹ TVÃ…NGSRENSNING VID START (Render)")
    
    # 1. DÃ¶da gamla processer fÃ¶rst
    kill_old_processes()
    
    # 2. Rensa databas-lÃ¥sningar
    cleanup_database_locks()
    
    # 3. Extra vÃ¤ntetid fÃ¶r att allt ska hinna "sÃ¤tta sig"
    print("â±ï¸  VÃ¤ntar 5 sekunder sÃ¥ allt hinner rensas...")
    time.sleep(5)
    
    print("âœ… TvÃ¥ngsrensning klar - fortsÃ¤tter med normal start")

os.chdir(ROOT)
from scrape_hh import scrape  # type: ignore[reportMissingImports]  # noqa: E402

def start_webserver_thread():
    """Startar webservern i en separat thread (bara pÃ¥ Render)"""
    if not IS_RENDER:
        return
        
    print("ğŸŒ Startar webserver-thread...")
    
    def run_webserver():
        try:
            # Ignorera SIGTERM i webserver-thread - lÃ¥t main process hantera det
            signal.signal(signal.SIGTERM, signal.SIG_IGN)
            
            # Skapa tomma databaser om de inte finns (pÃ¥ Render)
            if IS_RENDER:
                from utils.paths import POKER_DB, HEAVY_DB
                import sqlite3
                
                # Skapa minimala databaser om de inte finns
                for db_path in [POKER_DB, HEAVY_DB]:
                    if not db_path.exists():
                        print(f"ğŸ“¦ Skapar tom databas: {db_path}")
                        # Se till att parent directory finns
                        db_path.parent.mkdir(parents=True, exist_ok=True)
                        conn = sqlite3.connect(str(db_path))
                        conn.close()
                
                # Kontrollera frontend pÃ¥ Render
                frontend_path = Path(__file__).resolve().parent / "frontend" / "dist"
                if frontend_path.exists():
                    index_file = frontend_path / "index.html"
                    if index_file.exists():
                        print(f"âœ… Frontend byggd: {frontend_path}")
                    else:
                        print(f"âŒ index.html saknas: {index_file}")
                else:
                    print(f"âŒ Frontend dist saknas: {frontend_path}")
                    print("âš ï¸  Frontend kanske inte byggdes korrekt i Build Command")
            
            # Importera direkt istÃ¤llet fÃ¶r subprocess
            import uvicorn
            
            # Get port from environment variable (Render sets this) or default to 8000
            port = int(os.environ.get("PORT", 8000))
            print(f"ğŸŒ Webserver startar pÃ¥ port {port}...")
            print(f"ğŸ”— URL: https://promethius.onrender.com")
            
            # Kontrollera om porten Ã¤r upptagen
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(1)
                result = sock.connect_ex(('localhost', port))
                sock.close()
                if result == 0:
                    print(f"âš ï¸  Port {port} Ã¤r upptagen - dÃ¶dÃ¤r processer som anvÃ¤nder den")
                    # DÃ¶da processer som anvÃ¤nder vÃ¥r port
                    try:
                        subprocess.run(f"lsof -ti:{port} | xargs kill -9", shell=True, capture_output=True)
                    except:
                        pass
                    time.sleep(2)
            except:
                pass  # Ignore errors
            
            # VÃ¤nta lite sÃ¥ databaserna hinner skapas
            time.sleep(2)
            
            # KÃ¶r uvicorn direkt i threaden
            uvicorn.run(
                "app:app",
                host="0.0.0.0",
                port=port,
                reload=False,  # Aldrig reload pÃ¥ Render
                log_level="info",
                access_log=True
            )
        except Exception as e:
            import traceback
            print(f"âŒ KRITISKT FEL - Webserver-thread krashade: {e}")
            print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            print("ğŸ”„ FÃ¶rsÃ¶ker starta om webserver om 30 sekunder...")
            time.sleep(30)
            # Rekursiv restart
            run_webserver()
    
    web_thread = threading.Thread(target=run_webserver, daemon=False)  # INTE daemon!
    web_thread.start()
    
    # VÃ¤nta lÃ¤ngre sÃ¥ webservern hinner starta ordentligt  
    print("â±ï¸  VÃ¤ntar pÃ¥ att webserver ska starta...")
    time.sleep(10)
    print("âœ… Webserver-thread startad")

# â”€â”€ 2. HjÃ¤lpfunktioner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_config() -> dict[str, str]:
    kv: dict[str, str] = {}
    with open(ROOT / "config.txt", encoding="utf-8") as fh:
        for line in fh:
            if "=" in line:
                k, v = line.strip().split("=", 1)
                kv[k.strip().upper()] = v.strip()
    return kv

CFG = load_config()
STARTING_DATE = CFG["STARTING_DATE"]

print(f"ğŸŒ API: {CFG['BASE_URL']}")
print(f"   Organizer: {CFG['ORGANIZER']}")
print(f"   Event: {CFG['EVENT']}")
print()

def run_clean_start(skip_on_render: bool = True) -> bool:
    # PÃ¥ Render, skippa rensning om inte explicit begÃ¤rt
    if IS_RENDER and skip_on_render:
        print("ğŸš€ PÃ¥ Render - hoppar Ã¶ver rensning (anvÃ¤nd skip_on_render=False fÃ¶r att tvinga)")
        return True
        
    try:
        print("ğŸ§¹ KÃ¶r rensning...")
        result = subprocess.run([sys.executable, "clean_start.py"],
                                cwd=ROOT, capture_output=True, text=True, timeout=60)

        if result.returncode == 0:
            print("âœ… Rensning klar")
            if result.stdout.strip():
                print(f"   {result.stdout.strip()}")
            return True
        else:
            print(f"âŒ Rensning misslyckades: {result.stderr}")
            return False
    except subprocess.TimeoutExpired:
        print("â° Rensning tog fÃ¶r lÃ¥ng tid - avbryter")
        return False
    except Exception as e:
        print(f"âŒ Fel vid rensning: {e}")
        return False

def run_fetch_process(date_str: str, url: str | None, db: str | None,
                      skip_scripts: list[str] | None = None, no_scripts: bool = False) -> None:
    try:
        argv = ["scrape.py", date_str]
        if url:
            argv += ["--url", url]
        if db:
            argv += ["--db", db]
        if skip_scripts:
            argv += ["--skip-scripts"] + skip_scripts
        if no_scripts:
            argv += ["--no-scripts"]

        original_argv = sys.argv[:]
        sys.argv = argv

        scrape.main()

        sys.argv = original_argv

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  Scraping avbrutet fÃ¶r {date_str}")
        raise
    except Exception as e:
        print(f"âŒ Fel vid scraping fÃ¶r {date_str}: {e}")
        raise

def run_single_fetch(date_str: str, url: str | None, db: str | None,
                     skip_scripts: list[str] | None = None, no_scripts: bool = False) -> None:
    if not run_clean_start():
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return

    run_fetch_process(date_str, url, db, skip_scripts, no_scripts)

def run_loop(start_date: str, url: str | None, db: str | None,
             sleep_s: int = 300, max_workers: int = 1,
             skip_scripts: list[str] | None = None, no_scripts: bool = False,
             no_clean: bool = False) -> None:
    # Smart fÃ¶rsta-deploy-detektion pÃ¥ Render
    if IS_RENDER and not no_clean:
        from utils.paths import POKER_DB, HEAVY_DB, DB_DIR
        
        # Marker-fil fÃ¶r att veta om fÃ¶rsta deployen Ã¤r gjord
        marker_file = DB_DIR / ".first_deploy_done"
        
        if not marker_file.exists():
            print("ğŸ‰ FÃ–RSTA DEPLOYEN - rensar alla databaser fÃ¶r fresh start...")
            
            # Extra sÃ¤kerhet: DÃ¶da alla processer och rensa lÃ¥sningar
            kill_old_processes()
            cleanup_database_locks()
            
            # Hitta ALLA databas-filer rekursivt fÃ¶r total rensning
            print("ğŸ” SÃ¶ker efter ALLA databas-filer fÃ¶r total rensning...")
            search_dirs = [DB_DIR]
            if IS_RENDER:
                search_dirs.append(Path('/var/data'))
            
            all_db_files = []
            for search_dir in search_dirs:
                if search_dir.exists():
                    # Hitta alla filer som matchar vÃ¥ra databas-namn
                    patterns = ['poker.db*', 'heavy_analysis.db*']
                    for pattern in patterns:
                        all_db_files.extend(search_dir.rglob(pattern))
            
            # LÃ¤gg till kÃ¤nda filer ocksÃ¥
            known_db_files = [
                POKER_DB,
                HEAVY_DB,
                POKER_DB.with_suffix('.db-wal'),
                POKER_DB.with_suffix('.db-shm'),
                HEAVY_DB.with_suffix('.db-wal'),
                HEAVY_DB.with_suffix('.db-shm'),
            ]
            
            unique_db_files = list(set(known_db_files + all_db_files))
            
            print(f"   ğŸ“ Hittade {len(unique_db_files)} databas-filer att radera")
            
            deleted_count = 0
            for db_file in unique_db_files:
                if db_file.exists():
                    try:
                        db_file.unlink()
                        print(f"   âœ“ Raderade {db_file}")
                        deleted_count += 1
                    except Exception as e:
                        print(f"   âš ï¸  Kunde inte radera {db_file}: {e}")
            
            print(f"âœ… Raderade {deleted_count} databas-filer totalt")
            
            # KÃ¶r full rensning
            if not run_clean_start(skip_on_render=False):
                print("âŒ Kritisk: Kan inte starta utan lyckad fÃ¶rsta rensning")
                sys.exit(1)
            
            # Skapa marker-fil sÃ¥ vi vet att fÃ¶rsta deployen Ã¤r gjord
            marker_file.write_text(f"First deploy completed: {datetime.datetime.now().isoformat()}")
            print("âœ… FÃ¶rsta deployen klar - framtida restarts behÃ¥ller data")
            
        else:
            print("â™»ï¸  Inte fÃ¶rsta deployen - behÃ¥ller befintlig data (kontinuerlig drift)")
            # LÃ¤s nÃ¤r fÃ¶rsta deployen gjordes
            try:
                deploy_time = marker_file.read_text().strip()
                print(f"   {deploy_time}")
            except:
                pass
    elif not no_clean and not run_clean_start():
        # Lokal miljÃ¶ - respektera --no-clean flaggan
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return

    day = datetime.date.fromisoformat(start_date)

    def signal_handler(signum: int, frame: Any) -> None:
        if IS_RENDER and signum == signal.SIGTERM:
            # PÃ¥ Render: GÃ¶r ordentlig cleanup innan vi avslutar
            print(f"\nğŸ›‘ Fick SIGTERM pÃ¥ Render - gÃ¶r ordentlig cleanup...")
            
            try:
                # StÃ¤ng databas-connections
                cleanup_database_locks()
                print("âœ… Databas-cleanup klar")
            except:
                pass
            
            print("âœ… Graceful shutdown klar - avslutar")
            sys.exit(0)
        elif signum == signal.SIGTERM:
            print(f"\nğŸ›‘ Fick SIGTERM - avslutar...")
            sys.exit(0)
        else:
            print(f"\nğŸ›‘ Fick signal {signum} - stÃ¤nger av gracefully...")
            sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    batch_size = CFG.get("BATCH_SIZE", "500")
    print(f"ğŸ”„ Startar loop frÃ¥n {start_date}")
    print(f"   Batch-storlek: {batch_size} hÃ¤nder per dag")

    while True:
        try:
            current_date = day.isoformat()

            # KÃ¶r scraping synkront fÃ¶r att undvika extra processfork och sÃ¤nka CPU-toppar
            print(f"ğŸ”„ Startar scraping fÃ¶r {current_date}...")
            run_fetch_process(current_date, url, db, skip_scripts, no_scripts)
            print(f"âœ… Scraping klar fÃ¶r {current_date}")

            day += datetime.timedelta(days=1)

            if day == datetime.date.today():
                print("ğŸ•‘ VÃ¤ntar 10 minuter innan nÃ¤sta kÃ¶rning...")
                time.sleep(600)
            else:
                print(f"ğŸ•‘ VÃ¤ntar {sleep_s//60} min innan nÃ¤sta kÃ¶rning...")
                time.sleep(sleep_s)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  Loop avbruten av anvÃ¤ndare")
            break
        except Exception as e:
            print(f"âŒ Fel i loop: {e}")
            print(f"â­ï¸  Hoppar Ã¶ver {day.isoformat()} och fortsÃ¤tter...")
            day += datetime.timedelta(days=1)
            time.sleep(5)

# â”€â”€ 3. CLI-parse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ap = argparse.ArgumentParser(
    description="Automatisk poker scraping system"
)
_ = ap.add_argument("--date", help="Startdatum (default = STARTING_DATE frÃ¥n config.txt)")
_ = ap.add_argument("--url", help="Ã–verskriv BASE_URL")
_ = ap.add_argument("--db", help="Ã–verskriv DB-sÃ¶kvÃ¤g")
_ = ap.add_argument("--workers", type=int, default=1,
                    help="Antal worker-processer (default: 1)")
_ = ap.add_argument("--sleep", type=int, default=300,
                    help="Sovtid i sekunder mellan kÃ¶rningar (default: 300)")
_ = ap.add_argument("--skip-scripts", nargs="*", default=[],
                    help="Script att hoppa Ã¶ver")
_ = ap.add_argument("--no-scripts", action="store_true",
                    help="Hoppa Ã¶ver alla processing-scripts")
_ = ap.add_argument("--no-clean", action="store_true",
                    help="Hoppa Ã¶ver rensning (rekommenderat pÃ¥ Render)")

args = ap.parse_args()

# â”€â”€ 4. KÃ¶r vald handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸš€ Startar automatisk scraping...")
    
    # TVÃ…NGSMÃ„SSIG CLEANUP FÃ–RST (pÃ¥ Render)
    force_cleanup_on_start()
    
    # PÃ¥ Render, starta webservern fÃ¶rst
    if IS_RENDER:
        # FÃ¶rsÃ¶k med threading fÃ¶rst
        try:
            start_webserver_thread()
            print("ğŸŒ Render: Webserver + Scraping i samma process fÃ¶r maximal stabilitet")
        except Exception as e:
            print(f"âŒ Threading misslyckades: {e}")
            print("ğŸ”„ Startar webserver direkt istÃ¤llet...")
            
            # Backup: Starta webservern direkt utan scraping
            import uvicorn
            port = int(os.environ.get("PORT", 8000))
            print(f"ğŸŒ Backup: Startar webserver direkt pÃ¥ port {port}")
            uvicorn.run("app:app", host="0.0.0.0", port=port, reload=False)
            exit()  # Om vi nÃ¥r hit kÃ¶rdes aldrig scraping
    
    # Scraping-loop (kÃ¶rs bara om webserver startade i thread)
    start = args.date or STARTING_DATE
    run_loop(
        start, 
        args.url, 
        args.db, 
        args.sleep, 
        args.workers,
        args.skip_scripts, 
        args.no_scripts, 
        args.no_clean
    )
