#!/usr/bin/env python3
"""
main.py - Central startpunkt fÃ¶r poker scraping system

Huvudfunktioner:
- Hanterar initial cleanup och setup
- Startar scraping-loop fÃ¶r kontinuerlig datainsamling  
- PÃ¥ Render: Kombinerar scraping med webserver
- Hanterar graceful shutdown och process-management
"""

from __future__ import annotations
import argparse
import sys
import os
import time
import datetime
import subprocess
import sqlite3
from pathlib import Path
import signal
import threading
from typing import Any
import socket

# Import centraliserad path-hantering
sys.path.append(str(Path(__file__).resolve().parent))
from utils.paths import PROJECT_ROOT, POKER_DB, IS_RENDER

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Konfiguration och setup
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ROOT = PROJECT_ROOT
DB_PATH = POKER_DB.relative_to(ROOT) if not IS_RENDER else POKER_DB

print(f"ðŸ  Projektrot: {ROOT}")
print(f"ðŸ’¾ Database: {POKER_DB}")

os.chdir(ROOT)
from scrape_hh import scrape  # type: ignore[reportMissingImports]  # noqa: E402

def load_config() -> dict[str, str]:
    """LÃ¤ser konfiguration frÃ¥n config.txt."""
    kv: dict[str, str] = {}
    with open(ROOT / "config.txt", encoding="utf-8") as fh:
        for line in fh:
            if "=" in line:
                k, v = line.strip().split("=", 1)
                kv[k.strip().upper()] = v.strip()
    return kv

CFG = load_config()
STARTING_DATE = CFG["STARTING_DATE"]

print(f"ðŸŒ API: {CFG['BASE_URL']}")
print(f"   Organizer: {CFG['ORGANIZER']}")
print(f"   Event: {CFG['EVENT']}")
print()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cleanup och process-hantering
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def kill_old_processes() -> None:
    """FÃ¶rsÃ¶ker dÃ¶da gamla Python-processer (endast fÃ¶r Render)."""
    if not IS_RENDER:
        return
    
    # psutil inte tillgÃ¤ngligt pÃ¥ Render - skulle kunna implementeras senare
    print("â­ï¸  Hoppar Ã¶ver process-cleanup (psutil inte tillgÃ¤ngligt)")

def cleanup_database_locks() -> None:
    """Rensar SQLite WAL/SHM-filer och stÃ¤nger lÃ¥sningar."""
    try:
        from utils.paths import POKER_DB, HEAVY_DB, DB_DIR
        
        print("ðŸ” SÃ¶ker efter databas-filer...")
        
        # SÃ¶k efter databas-filer
        search_dirs = [DB_DIR]
        if IS_RENDER:
            search_dirs.append(Path('/var/data'))
        
        all_db_files = []
        patterns = ['poker.db*', 'heavy_analysis.db*']
        
        for search_dir in search_dirs:
            if search_dir.exists():
                for pattern in patterns:
                    all_db_files.extend(search_dir.rglob(pattern))
        
        # LÃ¤gg till kÃ¤nda databas-filer
        known_db_files = [
            POKER_DB, HEAVY_DB,
            POKER_DB.with_suffix('.db-wal'), POKER_DB.with_suffix('.db-shm'),
            HEAVY_DB.with_suffix('.db-wal'), HEAVY_DB.with_suffix('.db-shm'),
        ]
        
        unique_db_files = list(set(known_db_files + all_db_files))
        
        print(f"   ðŸ“ Hittade {len(unique_db_files)} databas-filer")
        
        # Checkpoint aktiva databaser
        _checkpoint_databases(unique_db_files)
        
        # Radera WAL/SHM-filer
        _remove_lock_files(unique_db_files)
        
    except Exception as e:
        print(f"âš ï¸  Fel vid databas-rensning: {e}")

def _checkpoint_databases(db_files: list[Path]) -> None:
    """GÃ¶r WAL checkpoint pÃ¥ alla aktiva databaser."""
    for db_file in db_files:
        if db_file.suffix == '.db' and db_file.exists():
            try:
                conn = sqlite3.connect(str(db_file))
                conn.execute("PRAGMA wal_checkpoint(TRUNCATE)")
                conn.close()
                print(f"   âœ“ Checkpoint: {db_file.name}")
            except Exception as e:
                print(f"   âš ï¸  Checkpoint misslyckades fÃ¶r {db_file.name}: {e}")

def _remove_lock_files(db_files: list[Path]) -> None:
    """Raderar WAL/SHM lÃ¥sfiler."""
    removed_count = 0
    for db_file in db_files:
        if db_file.name.endswith(('.db-wal', '.db-shm')) and db_file.exists():
            try:
                db_file.unlink()
                print(f"   âœ“ Raderade: {db_file.name}")
                removed_count += 1
            except Exception as e:
                print(f"   âš ï¸  Kunde inte radera {db_file.name}: {e}")
    
    if removed_count > 0:
        print(f"âœ… Rensade {removed_count} lÃ¥sfiler")
    else:
        print("âœ… Inga lÃ¥sfiler att rensa")

def force_cleanup_on_start() -> None:
    """TvÃ¥ngsmÃ¤ssig cleanup vid start (endast Render)."""
    if not IS_RENDER:
        return
        
    print("ðŸ§¹ TVÃ…NGSRENSNING VID START (Render)")
    
    kill_old_processes()
    cleanup_database_locks()
    
    print("â±ï¸  VÃ¤ntar 5 sekunder...")
    time.sleep(5)
    
    print("âœ… TvÃ¥ngsrensning klar")

def handle_first_deploy() -> bool:
    """Hanterar fÃ¶rsta deploy pÃ¥ Render med total databas-rensning."""
    from utils.paths import POKER_DB, HEAVY_DB, DB_DIR
    
    marker_file = DB_DIR / ".first_deploy_done"
    
    if marker_file.exists():
        print("â™»ï¸  Kontinuerlig drift - behÃ¥ller befintlig data")
        try:
            deploy_time = marker_file.read_text().strip()
            print(f"   {deploy_time}")
        except:
            pass
        return True
    
    print("ðŸŽ‰ FÃ–RSTA DEPLOYEN - total databas-rensning...")
    
    # Extra sÃ¤kerhet
    kill_old_processes()
    cleanup_database_locks()
    
    # Hitta och radera alla databas-filer
    db_files_deleted = _delete_all_database_files()
    
    print(f"âœ… Raderade {db_files_deleted} databas-filer")
    
    # KÃ¶r full rensning
    if not run_clean_start(skip_on_render=False):
        print("âŒ KRITISK: FÃ¶rsta rensning misslyckades")
        return False
    
    # Skapa marker
    marker_file.write_text(f"First deploy completed: {datetime.datetime.now().isoformat()}")
    print("âœ… FÃ¶rsta deployen klar")
    
    return True

def _delete_all_database_files() -> int:
    """Raderar alla databas-filer fÃ¶r fresh start."""
    from utils.paths import POKER_DB, HEAVY_DB, DB_DIR
    
    search_dirs = [DB_DIR]
    if IS_RENDER:
        search_dirs.append(Path('/var/data'))
    
    all_db_files = []
    patterns = ['poker.db*', 'heavy_analysis.db*']
    
    for search_dir in search_dirs:
        if search_dir.exists():
            for pattern in patterns:
                all_db_files.extend(search_dir.rglob(pattern))
    
    # LÃ¤gg till kÃ¤nda filer
    known_db_files = [
        POKER_DB, HEAVY_DB,
        POKER_DB.with_suffix('.db-wal'), POKER_DB.with_suffix('.db-shm'),
        HEAVY_DB.with_suffix('.db-wal'), HEAVY_DB.with_suffix('.db-shm'),
    ]
    
    unique_db_files = list(set(known_db_files + all_db_files))
    deleted_count = 0
    
    for db_file in unique_db_files:
        if db_file.exists():
            try:
                db_file.unlink()
                print(f"   âœ“ Raderade {db_file.name}")
                deleted_count += 1
            except Exception as e:
                print(f"   âš ï¸  Kunde inte radera {db_file.name}: {e}")
    
    return deleted_count

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Scraping-operationer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_clean_start(skip_on_render: bool = True) -> bool:
    """KÃ¶r clean_start.py script fÃ¶r initial rensning."""
    if IS_RENDER and skip_on_render:
        print("ðŸš€ PÃ¥ Render - hoppar Ã¶ver rensning")
        return True
        
    try:
        print("ðŸ§¹ KÃ¶r rensning...")
        result = subprocess.run(
            [sys.executable, "clean_start.py"],
            cwd=ROOT, 
            capture_output=True, 
            text=True, 
            timeout=60
        )

        if result.returncode == 0:
            print("âœ… Rensning klar")
            if result.stdout.strip():
                print(f"   {result.stdout.strip()}")
            return True
        else:
            print(f"âŒ Rensning misslyckades: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print("â° Rensning tog fÃ¶r lÃ¥ng tid")
        return False
    except Exception as e:
        print(f"âŒ Fel vid rensning: {e}")
        return False

def run_fetch_process(
    date_str: str, 
    url: str | None, 
    db: str | None,
    skip_scripts: list[str] | None = None, 
    no_scripts: bool = False
) -> None:
    """KÃ¶r scraping fÃ¶r ett specifikt datum."""
    try:
        # FÃ¶rbered arguments fÃ¶r scrape.py
        argv = ["scrape.py", date_str]
        
        if url:
            argv.extend(["--url", url])
        if db:
            argv.extend(["--db", db])
        if skip_scripts:
            argv.extend(["--skip-scripts"] + skip_scripts)
        if no_scripts:
            argv.append("--no-scripts")

        # KÃ¶r scrape.main() direkt istÃ¤llet fÃ¶r subprocess
        original_argv = sys.argv[:]
        sys.argv = argv
        
        scrape.main()
        
        sys.argv = original_argv

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  Scraping avbrutet fÃ¶r {date_str}")
        raise
    except Exception as e:
        print(f"âŒ Fel vid scraping fÃ¶r {date_str}: {e}")
        raise

def run_single_fetch(
    date_str: str, 
    url: str | None, 
    db: str | None,
    skip_scripts: list[str] | None = None, 
    no_scripts: bool = False
) -> None:
    """KÃ¶r scraping fÃ¶r ett enda datum med cleanup fÃ¶rst."""
    if not run_clean_start():
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return

    run_fetch_process(date_str, url, db, skip_scripts, no_scripts)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Signal handling
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def setup_signal_handlers() -> None:
    """SÃ¤tter upp signal handlers fÃ¶r graceful shutdown."""
    def signal_handler(signum: int, frame: Any) -> None:
        if IS_RENDER and signum == signal.SIGTERM:
            print(f"\nðŸ›‘ SIGTERM pÃ¥ Render - graceful shutdown...")
            
            try:
                cleanup_database_locks()
                print("âœ… Databas-cleanup klar")
            except:
                pass
            
            print("âœ… Graceful shutdown klar")
            sys.exit(0)
        else:
            print(f"\nðŸ›‘ Signal {signum} - avslutar...")
            sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Huvudloop
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_scraping_loop(
    start_date: str, 
    url: str | None, 
    db: str | None,
    sleep_s: int = 300,
    skip_scripts: list[str] | None = None, 
    no_scripts: bool = False,
    no_clean: bool = False, 
    in_thread: bool = False
) -> None:
    """Huvudloop fÃ¶r kontinuerlig scraping."""
    
    # Initial setup och cleanup
    if not _setup_initial_state(no_clean, in_thread):
        return
    
    # Setup signal handling (endast i main thread)
    if not in_thread:
        setup_signal_handlers()
    else:
        print("ðŸ”„ Scraping-thread: Hoppar Ã¶ver signal handling")

    # BÃ¶rja scraping-loop
    day = datetime.date.fromisoformat(start_date)
    batch_size = CFG.get("BATCH_SIZE", "500")
    
    print(f"ðŸ”„ Startar scraping-loop frÃ¥n {start_date}")
    print(f"   Batch-storlek: {batch_size} hÃ¤nder per dag")

    while True:
        try:
            current_date = day.isoformat()
            
            print(f"ðŸ”„ Scraping fÃ¶r {current_date}...")
            run_fetch_process(current_date, url, db, skip_scripts, no_scripts)
            print(f"âœ… Scraping klar fÃ¶r {current_date}")

            day += datetime.timedelta(days=1)
            
            # Olika vÃ¤ntetider beroende pÃ¥ om vi kommit ikapp dagens datum
            if day == datetime.date.today():
                print("ðŸ•‘ VÃ¤ntar 10 minuter (ikapp dagens datum)...")
                time.sleep(600)
            else:
                print(f"ðŸ•‘ VÃ¤ntar {sleep_s//60} min...")
                time.sleep(sleep_s)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  Loop avbruten av anvÃ¤ndare")
            break
        except Exception as e:
            print(f"âŒ Fel i loop fÃ¶r {day.isoformat()}: {e}")
            print(f"â­ï¸  Hoppar Ã¶ver och fortsÃ¤tter...")
            day += datetime.timedelta(days=1)
            time.sleep(5)

def _setup_initial_state(no_clean: bool, in_thread: bool) -> bool:
    """SÃ¤tter upp initial state fÃ¶r scraping-loop."""
    if IS_RENDER and not no_clean:
        # Render: Hantera fÃ¶rsta deploy
        if not handle_first_deploy():
            print("âŒ FÃ¶rsta deploy misslyckades")
            return False
    elif not no_clean and not run_clean_start():
        # Lokal: Respektera --no-clean flaggan
        print("âŒ Kan inte fortsÃ¤tta utan lyckad rensning")
        return False
    
    return True

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Render-specifik webserver-hantering
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def start_render_environment(
    start_date: str,
    url: str | None,
    db: str | None, 
    sleep_s: int,
    skip_scripts: list[str],
    no_scripts: bool,
    no_clean: bool
) -> None:
    """Startar scraping + webserver fÃ¶r Render deployment."""
    
    def run_scraping_background() -> None:
        """KÃ¶r scraping i bakgrund."""
        print("ðŸ”„ Startar scraping i bakgrund...")
        time.sleep(15)  # LÃ¥t webservern starta fÃ¶rst
        
        run_scraping_loop(
            start_date, url, db, sleep_s, skip_scripts, 
            no_scripts, no_clean, in_thread=True
        )
    
    # Starta scraping i bakgrundsthread
    scraping_thread = threading.Thread(target=run_scraping_background, daemon=True)
    scraping_thread.start()
    print("âœ… Scraping startad i bakgrund")
    
    # Skapa databaser om de inte finns
    _ensure_databases_exist()
    
    # Starta webserver som huvudprocess
    _start_webserver()

def _ensure_databases_exist() -> None:
    """Skapar tomma databaser om de inte finns."""
    try:
        from utils.paths import POKER_DB, HEAVY_DB
        
        for db_path in [POKER_DB, HEAVY_DB]:
            if not db_path.exists():
                print(f"ðŸ“¦ Skapar tom databas: {db_path.name}")
                db_path.parent.mkdir(parents=True, exist_ok=True)
                conn = sqlite3.connect(str(db_path))
                conn.close()
                
    except Exception as e:
        print(f"âš ï¸  Databas-skapande fel: {e}")

def _start_webserver() -> None:
    """Startar webserver som huvudprocess pÃ¥ Render."""
    import uvicorn
    
    port = int(os.environ.get("PORT", 8000))
    
    print(f"ðŸŒ Webserver som huvudprocess pÃ¥ port {port}")
    print(f"ðŸ”— URL: https://promethius.onrender.com")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info",
        access_log=True
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI och main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_argument_parser() -> argparse.ArgumentParser:
    """Skapar argument parser fÃ¶r CLI."""
    parser = argparse.ArgumentParser(
        description="Automatisk poker scraping system"
    )
    
    parser.add_argument("--date", help="Startdatum (default frÃ¥n config.txt)")
    parser.add_argument("--url", help="Ã–verskriv BASE_URL")
    parser.add_argument("--db", help="Ã–verskriv DB-sÃ¶kvÃ¤g")
    parser.add_argument("--workers", type=int, default=1,
                       help="Antal worker-processer (default: 1)")
    parser.add_argument("--sleep", type=int, default=300,
                       help="Sovtid mellan kÃ¶rningar i sekunder (default: 300)")
    parser.add_argument("--skip-scripts", nargs="*", default=[],
                       help="Script att hoppa Ã¶ver")
    parser.add_argument("--no-scripts", action="store_true",
                       help="Hoppa Ã¶ver alla processing-scripts")
    parser.add_argument("--no-clean", action="store_true",
                       help="Hoppa Ã¶ver initial rensning")
    
    return parser

def main() -> None:
    """Huvudfunktion som orchestrerar hela systemet."""
    print("ðŸš€ Startar automatisk scraping...")
    
    # TvÃ¥ngsmÃ¤ssig cleanup fÃ¶rst (Render)
    force_cleanup_on_start()
    
    # Parse arguments
    parser = create_argument_parser()
    args = parser.parse_args()
    
    start_date = args.date or STARTING_DATE
    
    if IS_RENDER:
        # Render: Scraping + webserver
        start_render_environment(
            start_date, args.url, args.db, args.sleep,
            args.skip_scripts, args.no_scripts, args.no_clean
        )
    else:
        # Lokal utveckling: Bara scraping
        run_scraping_loop(
            start_date, args.url, args.db, args.sleep,
            args.skip_scripts, args.no_scripts, args.no_clean,
            in_thread=False
        )

if __name__ == "__main__":
    main()
